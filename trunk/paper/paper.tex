\documentclass{memoir}

\usepackage{graphicx}
\usepackage{hyperref}
\usepackage{memhfixc}

\title{Jaigo Technical Report}
\author{Sean Foy \and Noel Weichbrodt}

\begin{document}
	
\newtheorem{defn}{Definition}

\frontmatter
\begin{titlingpage}
\maketitle

\begin{abstract}
Despite its elegantly simple rules, Go's complexity as a game of deterministic strategy has made it a recurring subject in studies of artificial intelligence and game theory \cite{Muller2002}.
\end{abstract}
\end{titlingpage}

\tableofcontents
\listoftables

\mainmatter
\chapter{Introduction}
%Include background materials and define the problem and scope of your project.
Go is a two-player board game which originated in Ancient China and remains one of the most richly complex games of strategy today. The objective is to control more area or territory than one's opponent on the game board. The game is played on a square line grid; the standard size of this grid is 19 x 19, though 13 x 13 and 9 x 9 grids are used occasionally. Players place stones -- either black or white -- at the intersecting points of the grid to signify control of that position. Once placed on the board a stone has a number of liberties -- unoccupied grid positions which are orthogonally adjacent to that stone. The goal of the game is to claim as much territory as possible by forming chains (contiguous extensions of stones of the same color) which cannot be captured by one's opponent. A stone or chain is captured and removed from the board when it has no liberties, the result of being surrounded by stones of the opposing color.

Players are not allowed to commit ``suicide'' with their stones, that is, they may not play into a spot where a stone would have no liberties. This prohibition actually enables players to create certain arrangements of stones which cannot be captured. Players are also forbidden from repeating one of the previous two states of the game; players cannot repeat their previous move. This is known as the Ko rule. At each turn, a player can either place a stone or pass. The game ends when both players pass consecutively on a turn.

Go players are classified by their skill into equivalence classes called kyu and dan. A beginning player might have a rank of 30 kyu, while a more experienced player might be 15kyu. Avid amateurs and professionals who outrank 1 kyu fill the range from 1 dan (low) to 8 dan (high) and on to 1 professional dan (low) to 10p (high).

Game theorists would describe Go as a zero-sum, perfect information, partisan, deterministic strategy game. In zero-sum games, the utility of any action with respect to player a is the additive inverse of the utility of that action with respect to player b. Perfect information games are fully observable in AI parlance. Go has a turn-taking structure, so it is partisan (i.e., some moves are available to only one player). There is no element of chance in Go. These characteristics invite comparison with games such as Chess.

While chess eventually yielded to clever hardware and algorithms, the sheer state-space of Go has rendered specialize search approaches weak. In 1965, noted statistician I.J. Good presciently commented:

\begin{quote}
Go on a computer? -- In order to programme [sic] a computer to play a reasonable game of Go -- rather than merely a legal game -- it is necessary to formalise the principles of good strategy, or to design a learning programme. The principles are more qualitative and mysterious than in chess, and depend more on judgment. So I think it will be even more difficult to programme a computer to play a reasonable game of Go than of chess. \cite{Good65}
\end{quote}

Unlike many similar problems that were also announced in this manner, Go remains both a challenging and tantalizing problem.

Two major factors make computer Go more difficult to program than computer Chess:
\begin{enumerate}
  \item Go is PSPACE-hard with a branching factor of 361, and so is not amenable to brute force searching.
  \item The traditional concepts and representations of the state of the board do not translate easily to traditional areas of AI research.
\end{enumerate}

\chapter{Related theory and practice}
\section{Board representation}
With 3361 board states, and perhaps 10768 games, representing the board may be the most difficult part of writing a go engine.

The exploration of alternative future board states often yields duplicate (potential) states; it is helpful to memorize board evaluation such that a board state may be evaluated only once, regardless of the paths by which it is reached \cite{Zobrist1970b}. The Zobrist hash function is useful in this capacity: (reduce xor (map f board-positions)), $f: (x, y, color) \rightarrow Z$.

There are traditional concepts in go of blocks and eyes. Blocks are simply contiguously-connected stones of the same color. Eyes are empty spaces which are completely surrounded by stones of the same color. A good implementation of computer Go will represent these concepts, as they provide vital information when generating moves, evaluating the state of the board, and in scoring the board. 

\section{Known techniques}
Search techniques have been successful in games including Chess, but they have been much less effective in Go. The large branching factor of Go prohibits exhaustive search. Wolfe has shown by reduction from 3-QBF that Go endgames are PSPACE-hard \cite{Wolfe} and Go itself is EXPTIME-complete \cite{Burmeister}, so it is unlikely that any algorithm can guarantee optimal and efficient play. Computer Go is thus focused on approximation algorithms, and suboptimal or incomplete but empirically successful heuristic searches. Minimax with $\alpha$-$\beta$ pruning and the anytime beam stack search methods are of limited use given the very short horizon and absence of good heuristics for Go.

The difficulty of formalizing the heuristics used by humans motivates us to consider applying machine learning algorithms to pattern-matching in Go. Researchers including \cite{Enzenberger96} have enjoyed limited success with neural networks, but both training and playing are slow, and feature vector characterization is difficult. Strategies for overcoming the need for a priori knowledge in feature vector formulation and connection weights include constructive and genetic algorithms. Unfortunately, experiments with these techniques have yielded ``erratic and unorganized'' play despite ``prohibitively large'' time requirements for playing on full-size boards \cite{RichardsMM98}.

Br\"ugmann's approach plays games by choosing moves randomly according to probability distributions found by simulated annealing; the moves are evaluated according to their occurrence in successful games. A key insight from this research is that moves can be iteratively reprioritized by observed value rather than played in some fixed order; this is crucial for the simulated annealing application \cite{Bruegmann93}.

\chapter{Current Issues}

There are several significant issues to consider when programming computer Go. First, it is difficult to find an appropriate evaluation function. The human heuristics are vague, and the parameters for their application  are even more vague. Zobrist divided the game into phases for the purpose of selecting evaluation functions \cite{Zobrist1970b}. On the other hand, Ryder distinguished between tactical and strategic utility \cite{Burmeister}.

Second, there is a fight between optimizing the main loop -- that is, evaluating the board -- versus optimizing the small loops (given a board evaluation, local tricks to improve evaluation function). There is yet no standard, robust board evaluation algorithm. If a main board evaluation loop is established for playing computer Go and optimizations are made to the smaller evaluation functions within the loop, this would change the way the board is evaluated.  However, though such developments would potentially better the speed, completeness, or accuracy of the evaluation, they may also potentially damage the smaller evaluation functions.

Third, while genetic algorithms and neural networks initially seemed promising, no commercial package uses them due to lack of speed.

Thus, if all older techniques are inadequate and new techniques do not pan out, whither computer Go? Our project seeks to create a JavaScript-based Go-engine. JavaScript is a dynamically typed, imperative language that supports the functional and object-oriented paradigms \cite{ECMA-262}. It is ubiquitous due to its inclusion in nearly every Web browser, and recently has enjoyed a surge of popularity among programmers due to the availability of cross-platform libraries and the success of applications such as GMail. As professional programmers, we viewed this project as an opportunity to explore not only AI but also to pursue our renewed interest in the JavaScript language. Also, JavaScript is the only supported means of developing iPhone applications. iPhone is an intrinsically interesting platform; its communication capabilities and computational limitations heighten the interest.

\chapter{Interaction/UI}

We decided that our software should be interoperable with other Go software, allowing us to focus on the AI and making our software more useful. The Go Text Protocol \cite{GTP} is a defacto standard for interoperability, so we have focused our effort on implementing the role of the engine in the GTP. Besides providing an interface to competitive engines and automated testing frameworks, it allows us to avoid writing our own UI by reusing any of several existing UI implementations. During early development, we used a simple set of HTML input controls to interact with the engine via GTP.

\chapter{Scoring}

The board is scored using Benson's Algorithm \cite{Benson76}. ``c'' stands for black or white, ``-c'' for the opposite color. Each point of the board is, of course, either black, white or empty.

\begin{defn}A c-chain is a non-empty maximum connected set of c points.
\end{defn}

\begin{defn}A c-region is a non-empty maximum connected set of -c and empty points.
\end{defn}

\begin{defn}
A c-chain is unconditionally alive if and only if it belongs to a set of c-chains S such that every chain B in S is adjacent to at least two c-regions R that satisfy:

\begin{enumerate}
  \item (P1) all empty points in R are adjacent to B, and 

  \item (P2) all c-chains adjacent to R belong to S.
\end{enumerate}
\end{defn}

\chapter{Engine choice}
There are a number of Go engines, so we sought to extend an existing engine rather than write something completely new. We could not find an engine in JavaScript, so the first order of business was to choose an engine to port. Our criteria for choosing an engine was simple: What is the engine with the smallest (estimated) expression in JavaScript and the highest kyu ranking?

We implemented two different move choice engines, each of which provides a different playing experience. SimpleGo v1, a 50kyu greedy search move generator which picks a random move from list of moves with worst opponent score. Crawler, an unranked move generator which analyzes the current blocks on the board and picks the move that both connects to a block and results in the largest number of liberties for the block.

\chapter{Technical details}
%Code Listing
- Implementation of Benson's algorithm for determining unconditional life: Analyze\_Color\_Unconditional\_Status
- Greedy Search algorithm: select\_scored\_move
- Crawler algorithm: select\_crawler\_move

\chapter{Discussions, observations, and comparisons}
We implemented representations of the board, the game, eyes, and blocks; scoring for color and blocks based on Benson's algorithm; two move choice engines based on two different algorithms; and numerous language-specific utilities. Our goals were compactness and speed due to the target platform limitations.

Due to issues with the jaigo board representation, our measurements were limited to the first 100 moves.

Regarding compactness, the total size of all jaigo files, including images, scripts, and html, was 102221 bytes for our initial release. The full implementation of the jaigo code is 66071 bytes \cite{SpeedReport}.

Regarding speed, we do not anticipate that the choice of processor and platform of any modern PC will have a significant change to the performance of jaigo.

\tref{table:first50} shows the first 50 moves on a 19x19 board with human (black) versus crawler (white).
\begin{table}
  \rotatebox{90}{
    \begin{tabular}{ccccccccc} \toprule
      Function & Calls & Percent & Own Time (ms) & Time (ms) & Avg (ms) & Min (ms) & Max (ms) & File\\ \midrule
      (no name) & 109675 & 25.68 & 14310.594 &	36908.812 &	0.337 &	0.059	& 1593.542	& simple\_go.js (line 407)\\
      flood\_mark & 1618 & 14.17 & 7897.73 & 25481.245 & 15.749 & 0.162 & 1635.18 & simple\_go.js (line 807)\\
      (no name) &	194678 &	11.75	& 6551.626 &	6554.733 &	0.034 &	0.008 &	1555.243 &	simple\_go.js (line 819)\\
      string\_as\_move &	56065 &	7.48 &	4168.485 &	4169.549 &	0.074 &	0.011 &	1591.844 &	simple\_go.js (line 192)\\
      iterate	& 109676 &	7.19 &	4005.749 &	22595.463 &	0.206 &	0.011 &	1593.499 &	simple\_go.js (line 391)\\
      (no name) &	283642 &	4.9 &	2732.499 &	18589.343 &	0.066 &	0.015 &	1593.144 &	simple\_go.js (line 416)\\
      iterateOwnProperties &	5811	& 4.38	& 2440.378 &	2847.852 &	0.49 &	0.004 &	2.917 &	simple\_go.js (line 132)\\
      Set\_Goban &	2150 &	3.53 &	1968.651 &	1969.095 &	0.916 &	0.004 &	942.058 &	simple\_go.js (line 528)\\
      (no name) &	42734 &	2.99 &	1666.478 &	1666.716 &	0.039 &	0.008 &	935.83 &	simple\_go.js (line 835)\\
      update &	3662 &	2.9 &	1613.61 &	1614.099 &	0.441 &	0.004 &	1560.416 &	simple\_go.js (line 117)\\
      Add\_Block &	2340 &	2.8 &	1559.92 &	1560.774 &	0.667 &	0.007 &	1529.63 &	simple\_go.js (line 757)\\
      Calculate\_Neighbour &	448 &	2.67 &	1487.337 &	12205.939 &	27.245 &	0.019 &	1579.849 &	simple\_go.js (line 829)\\
      Simple\_Same\_Block &	2149 &	1.93 &	1073.573 &	8185.472 &	3.809 &	0.002 &	1556.376 &	simple\_go.js (line 606)\\
      List\_Block\_Liberties &	3210 &	1.56 &	871.609 &	5057.619 &	1.576 &	0.012 &	1593.058 &	simple\_go.js (line 863)\\ \bottomrule
  \end{tabular}}
  \caption{First 50 moves on a 19x19 board}
  \label{table:first50}
\end{table}

\tref{table:first100} shows the first 100 moves of a game on a 19x19 board, with crawler (black) versus crawler (white).

\begin{table}
  \rotatebox{90}{
    \begin{tabular}{ccccccccc} \toprule
      Function & Calls & Percent & Own Time & Time & Avg & Min & Max & File\\	\midrule
      (no name) &	404494 &	32.8 &	71255.203 &	147518.241 &	0.365 &	0.059 &	1650.149 &	simple\_go.js (line 407)\\
      flood\_mark &	3838 &	15.94 &	34634.022 &	96713.52 &	25.199 &	0.206 &	1736.537 &	simple\_go.js (line 807)\\
      iterate &	404495 &	8.75 &	19004.696 &	76254.33 &	0.189 &	0.011 &	1650.101 &	simple\_go.js (line 391)\\
      (no name) &	735190 &	8.72 &	18941.197 &	18941.987 &	0.026 &	0.008 &	1572.648 &	simple\_go.js (line 819)\\
      string\_as\_move &	242765 &	5.86 &	12724.373	& 12725.279 &	0.052 &	0.011 &	1629.186 &	simple\_go.js (line 192)\\
      (no name) &	1041519 &	4.7 &	10209.513 &	57248.372 &	0.055 &	0.015 &	1649.869 &	simple\_go.js (line 416)\\
      List\_Block\_Liberties &	7706 &	4.02 &	8727.331 &	21457.809 &	2.785 &	0.013 &	1630.607 &	simple\_go.js (line 863)\\
      iterateOwnProperties &	14752 &	3.68 &	7985.019 &	9340.503 &	0.633 &	0.004 &	2.419 &	simple\_go.js (line 132)\\
      update &	8742 &	3.18 &	6911.102 &	6911.93 &	0.791 &	0.004 &	1648.007 &	simple\_go.js (line 117)\\
      Calculate\_Neighbour &	661 &	3.03 &	6593.032 &	60385.478 &	91.355 &	0.115 &	1679.244 &	simple\_go.js (line 829)\\
      (no name) &	160414 &	2.51 &	5444.827 &	5445.809 &	0.034	& 0.008 &	944.464 &	simple\_go.js (line 835)\\
      Add\_Stone &	6010 &	1.1 &	2392.214	& 191461.602	& 31.857 &	1.524 &	1785.447 &	simple\_go.js (line 641)\\ \bottomrule
    \end{tabular}}
  \caption{First 100 moves on a 19x19 board}
  \label{table:first100}
\end{table}

Median move response time for 10 games into the first 50 moves was was 1 second, with the high being 3 seconds and the low being unmeasurable.

On an iPhone over 54mbps 802.11g wifi with a full signal connected to a 3mbps cable modem, the median jaigo load time was 5 seconds, with the initial load time being the longest measurement at 15 seconds. On an iPhone over AT\&T 2.5G EDGE with a full signal, the median jaigo load time was 21 seconds, with a low of 17 seconds and a high of 30 seconds.

Median move times in other go engines (gnugo especially)?

\chapter{Recommendations, especially for future work and unsolved issues}
We feel that the choice of browser is more important than the choice of computing platform for the performance of jaigo. Our anecdotal experience and those of others on the Web show that there is an order of magnitude difference between popular browsers for some JavaScript operations. However, we have not carefully studied this issue.%http://therealcrisp.xs4all.nl/blog/2006/12/09/string-performance-in-internet-explorer/

The performance of $\alpha-\beta$ search pruning in javascript should be investigated. like SimpleGo v3, a 30kyu $\alpha$-$\beta$ pruned search move generator.

There is much more optimization and correctness work to be done to the jaigo board and game representations. For example, the move speed of jaigo could be measured on many diverse computing platforms. Jaigo could be also used as a "widget", a popular way of packaging small javascript and html applications into a format that is used by many different web sites and operating systems such as Windows Vista, Mac OS X, Facebook, Google, and others.

There are many open issues being tracked by the jaigo project at this time. Addressing them may lead to better, more correct performance. We anticipate continuing work on this project.

\backmatter
\bibliography{paper}
\bibliographystyle{plain}
\end{document}
